import torch
import torch.nn as nn
from torch.utils.data import DataLoader
import pandas as pd
import numpy as np
import os
import glob
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    confusion_matrix, roc_curve, auc
)

# å¯¼å…¥è®­ç»ƒè„šæœ¬ä¸­çš„æ¨¡å‹ç±»
from train import PhishingCNN1D, PhishingDataset

class MultiModelEvaluator:
    """å¤šæ¨¡å‹è¯„ä¼°å™¨ - è¯„ä¼°5ä¸ªä¿å­˜çš„æ¨¡å‹å¹¶æ‰¾å‡ºæœ€ä½³æ¨¡å‹"""
    def __init__(self, model_dir='saved_models'):
        self.model_dir = model_dir
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.models = {}
        self.results = {}
        
    def load_all_models(self):
        """åŠ è½½ç›®å½•ä¸­çš„æ‰€æœ‰æ¨¡å‹"""
        model_files = glob.glob(os.path.join(self.model_dir, 'best_model_fold_*.pth'))
        
        if not model_files:
            print(f"é”™è¯¯ï¼šåœ¨ {self.model_dir} ç›®å½•ä¸­æœªæ‰¾åˆ°æ¨¡å‹æ–‡ä»¶")
            print("æ¨¡å‹æ–‡ä»¶ååº”ç±»ä¼¼: best_model_fold_1.pth, best_model_fold_2.pth ç­‰")
            return 0
        
        print(f"æ‰¾åˆ° {len(model_files)} ä¸ªæ¨¡å‹æ–‡ä»¶")
        
        for model_path in sorted(model_files):
            # ä»æ–‡ä»¶åæå–æŠ˜æ•°
            filename = os.path.basename(model_path)
            fold_num = int(filename.split('_fold_')[1].split('.')[0])
            print(f"åŠ è½½ç¬¬ {fold_num} æŠ˜æ¨¡å‹...")
            
            # åŠ è½½æ£€æŸ¥ç‚¹
            checkpoint = torch.load(model_path, map_location='cpu')
            
            # åˆ›å»ºæ¨¡å‹å®ä¾‹
            model = PhishingCNN1D(input_features=checkpoint.get('input_features', 30))
            model.load_state_dict(checkpoint['model_state_dict'])
            model.to(self.device)
            model.eval()
            
            self.models[fold_num] = {
                'model': model,
                'path': model_path,
                'checkpoint': checkpoint
            }
        
        return len(self.models)
    
    def evaluate_single_model(self, model_dict, test_loader, threshold=0.5):
        """è¯„ä¼°å•ä¸ªæ¨¡å‹"""
        model = model_dict['model']
        model.eval()
        
        all_predictions = []
        all_probabilities = []
        all_labels = []
        
        with torch.no_grad():
            for data, target in test_loader:
                data, target = data.to(self.device), target.to(self.device)
                output = model(data)
                all_probabilities.extend(output.cpu().numpy())
                all_labels.extend(target.cpu().numpy())
        
        # è½¬æ¢ä¸ºäºŒè¿›åˆ¶é¢„æµ‹
        all_predictions = (np.array(all_probabilities) > threshold).astype(int)
        all_labels = np.array(all_labels)
        
        # è®¡ç®—æŒ‡æ ‡
        metrics = {
            'accuracy': accuracy_score(all_labels, all_predictions),
            'precision': precision_score(all_labels, all_predictions, zero_division=0),
            'recall': recall_score(all_labels, all_predictions, zero_division=0),
            'f1': f1_score(all_labels, all_predictions, zero_division=0)
        }
        
        # è®¡ç®—æ··æ·†çŸ©é˜µ
        cm = confusion_matrix(all_labels, all_predictions)
        metrics['confusion_matrix'] = cm
        metrics['tn'], metrics['fp'], metrics['fn'], metrics['tp'] = cm.ravel()
        
        # è®¡ç®—ROC AUC
        if len(np.unique(all_labels)) > 1:
            fpr, tpr, _ = roc_curve(all_labels, all_probabilities)
            metrics['roc_auc'] = auc(fpr, tpr)
        
        return metrics
    
    def evaluate_all_models(self, test_csv_path, batch_size=32):
        """è¯„ä¼°æ‰€æœ‰æ¨¡å‹å¹¶æ‰¾å‡ºæœ€ä½³æ¨¡å‹"""
        print("=" * 70)
        print(f"å¼€å§‹è¯„ä¼° {len(self.models)} ä¸ªæ¨¡å‹")
        print(f"æµ‹è¯•é›†: {test_csv_path}")
        print("=" * 70)
        
        # æ£€æŸ¥æµ‹è¯•é›†æ˜¯å¦å­˜åœ¨
        if not os.path.exists(test_csv_path):
            print(f"é”™è¯¯ï¼šæµ‹è¯•é›†æ–‡ä»¶ä¸å­˜åœ¨: {test_csv_path}")
            return None
        
        # åŠ è½½æµ‹è¯•æ•°æ®
        test_dataset = PhishingDataset(test_csv_path)
        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)
        
        print(f"æµ‹è¯•é›†å¤§å°: {len(test_dataset)} æ ·æœ¬")
        print(f"æ­£æ ·æœ¬æ•°: {sum(test_dataset.labels == 1)}, è´Ÿæ ·æœ¬æ•°: {sum(test_dataset.labels == 0)}")
        print("-" * 70)
        
        # è¯„ä¼°æ¯ä¸ªæ¨¡å‹
        for fold_num, model_dict in self.models.items():
            print(f"è¯„ä¼°ç¬¬ {fold_num} æŠ˜æ¨¡å‹...")
            metrics = self.evaluate_single_model(model_dict, test_loader)
            self.results[fold_num] = metrics
            
            # æ‰“å°ç»“æœ
            print(f"  ğŸ“Š F1åˆ†æ•°:    {metrics['f1']:.4f}")
            print(f"  âœ… å‡†ç¡®ç‡:    {metrics['accuracy']:.4f}")
            print(f"  ğŸ¯ ç²¾ç¡®ç‡:    {metrics['precision']:.4f}")
            print(f"  ğŸ” å¬å›ç‡:    {metrics['recall']:.4f}")
            if 'roc_auc' in metrics:
                print(f"  ğŸ“ˆ ROC AUC:   {metrics['roc_auc']:.4f}")
            print()
        
        # æ‰¾å‡ºæœ€ä½³æ¨¡å‹ï¼ˆåŸºäºF1åˆ†æ•°ï¼‰
        if self.results:
            best_fold = max(self.results, key=lambda x: self.results[x]['f1'])
            return best_fold
        return None
    
    def print_summary(self, best_fold):
        """æ‰“å°è¯„ä¼°æ±‡æ€»"""
        print("\n" + "=" * 70)
        print("æ¨¡å‹è¯„ä¼°æ±‡æ€»")
        print("=" * 70)
        
        # æ‰“å°å„æ¨¡å‹ç»“æœè¡¨æ ¼
        print("\nå„æ¨¡å‹æ€§èƒ½å¯¹æ¯” (æŒ‰F1åˆ†æ•°æ’åº):")
        print("-" * 70)
        print(f"{'æŠ˜æ•°':^5} | {'F1åˆ†æ•°':^8} | {'å‡†ç¡®ç‡':^8} | {'ç²¾ç¡®ç‡':^8} | {'å¬å›ç‡':^8}")
        print("-" * 70)
        
        sorted_folds = sorted(self.results.items(), key=lambda x: x[1]['f1'], reverse=True)
        
        for fold_num, metrics in sorted_folds:
            is_best = "â­" if fold_num == best_fold else " "
            print(f"{is_best}{fold_num:^4} | {metrics['f1']:^8.4f} | "
                  f"{metrics['accuracy']:^8.4f} | {metrics['precision']:^8.4f} | "
                  f"{metrics['recall']:^8.4f}")
        print("-" * 70)
        
        # æ‰“å°æœ€ä½³æ¨¡å‹è¯¦æƒ…
        best_metrics = self.results[best_fold]
        print(f"\nğŸ† æœ€ä½³æ¨¡å‹: ç¬¬ {best_fold} æŠ˜")
        print(f"   æ¨¡å‹æ–‡ä»¶: {os.path.basename(self.models[best_fold]['path'])}")
        print(f"   F1åˆ†æ•°:   {best_metrics['f1']:.4f}")
        print(f"   å‡†ç¡®ç‡:   {best_metrics['accuracy']:.4f}")
        print(f"   ç²¾ç¡®ç‡:   {best_metrics['precision']:.4f}")
        print(f"   å¬å›ç‡:   {best_metrics['recall']:.4f}")
        if 'roc_auc' in best_metrics:
            print(f"   ROC AUC:  {best_metrics['roc_auc']:.4f}")
        
        # æ˜¾ç¤ºæ··æ·†çŸ©é˜µè¯¦æƒ…
        print(f"\næ··æ·†çŸ©é˜µåˆ†æ:")
        print(f"  çœŸé˜´æ€§(TN): {best_metrics['tn']} - æ­£å¸¸ç½‘ç«™è¢«æ­£ç¡®è¯†åˆ«")
        print(f"  å‡é˜³æ€§(FP): {best_metrics['fp']} - æ­£å¸¸ç½‘ç«™è¢«è¯¯åˆ¤ä¸ºé’“é±¼ç½‘ç«™")
        print(f"  å‡é˜´æ€§(FN): {best_metrics['fn']} - é’“é±¼ç½‘ç«™è¢«è¯¯åˆ¤ä¸ºæ­£å¸¸ç½‘ç«™")
        print(f"  çœŸé˜³æ€§(TP): {best_metrics['tp']} - é’“é±¼ç½‘ç«™è¢«æ­£ç¡®è¯†åˆ«")
        
        # è®¡ç®—ç»Ÿè®¡é‡
        all_f1_scores = [m['f1'] for m in self.results.values()]
        avg_f1 = np.mean(all_f1_scores)
        std_f1 = np.std(all_f1_scores)
        
        print(f"\nğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
        print(f"  å¹³å‡F1åˆ†æ•°: {avg_f1:.4f} Â± {std_f1:.4f}")
        print(f"  F1åˆ†æ•°èŒƒå›´: [{min(all_f1_scores):.4f} - {max(all_f1_scores):.4f}]")
        print(f"  æ¨¡å‹ç¨³å®šæ€§: {'é«˜' if std_f1 < 0.02 else 'ä¸­ç­‰' if std_f1 < 0.05 else 'è¾ƒä½'}")
    
    def get_best_model_info(self, best_fold):
        """è·å–æœ€ä½³æ¨¡å‹ä¿¡æ¯"""
        if best_fold in self.models:
            return {
                'fold': best_fold,
                'path': self.models[best_fold]['path'],
                'metrics': self.results[best_fold]
            }
        return None

# ä¸»å‡½æ•°
def main():
    """ä¸»è¯„ä¼°å‡½æ•°"""
    # é…ç½®
    model_dir = 'C:/Users/MI/Phishing-website/saved_models'  # æ¨¡å‹ä¿å­˜ç›®å½•
    test_csv_path = "C:/Users/MI/Phishing-website/data/independent_test.csv"  # æµ‹è¯•é›†è·¯å¾„
    
    # åˆ›å»ºè¯„ä¼°å™¨
    evaluator = MultiModelEvaluator(model_dir)
    
    # åŠ è½½æ‰€æœ‰æ¨¡å‹
    model_count = evaluator.load_all_models()
    if model_count == 0:
        return
    
    # è¯„ä¼°æ‰€æœ‰æ¨¡å‹å¹¶æ‰¾å‡ºæœ€ä½³æ¨¡å‹
    best_fold = evaluator.evaluate_all_models(test_csv_path)
    
    if best_fold is not None:
        # æ‰“å°æ±‡æ€»ç»“æœ
        evaluator.print_summary(best_fold)
        
        # è·å–æœ€ä½³æ¨¡å‹ä¿¡æ¯
        best_model_info = evaluator.get_best_model_info(best_fold)
        
        # æä¾›ä½¿ç”¨æœ€ä½³æ¨¡å‹çš„ç¤ºä¾‹
        print("\n" + "=" * 70)
        print("å¦‚ä½•ä½¿ç”¨æœ€ä½³æ¨¡å‹è¿›è¡Œé¢„æµ‹")
        print("=" * 70)
        
        if best_model_info:
            print(f"æœ€ä½³æ¨¡å‹æ–‡ä»¶: {best_model_info['path']}")
            print(f"\nåŠ è½½å’Œä½¿ç”¨ä»£ç ç¤ºä¾‹:")
            print("```python")
            print(f"# åŠ è½½æœ€ä½³æ¨¡å‹")
            print(f"checkpoint = torch.load(r'{best_model_info['path']}', map_location='cpu')")
            print(f"")
            print(f"# åˆ›å»ºæ¨¡å‹å¹¶åŠ è½½æƒé‡")
            print(f"model = PhishingCNN1D(input_features=checkpoint.get('input_features', 30))")
            print(f"model.load_state_dict(checkpoint['model_state_dict'])")
            print(f"model.eval()")
            print(f"")
            print(f"# é¢„æµ‹å•ä¸ªæ ·æœ¬ï¼ˆ30ä¸ªç‰¹å¾ï¼‰")
            print(f"def predict_phishing(features):")
            print(f"    # features: åŒ…å«30ä¸ªç‰¹å¾çš„åˆ—è¡¨æˆ–numpyæ•°ç»„")
            print(f"    features_tensor = torch.tensor(features, dtype=torch.float32)")
            print(f"    features_tensor = features_tensor.unsqueeze(0).unsqueeze(0)  # [1, 1, 30]")
            print(f"    with torch.no_grad():")
            print(f"        prediction = model(features_tensor)")
            print(f"    # é¢„æµ‹å€¼ > 0.5 è¡¨ç¤ºé’“é±¼ç½‘ç«™ï¼Œâ‰¤ 0.5 è¡¨ç¤ºæ­£å¸¸ç½‘ç«™")
            print(f"    return 'é’“é±¼ç½‘ç«™' if prediction.item() > 0.5 else 'æ­£å¸¸ç½‘ç«™'")
            print("```")
            
            print(f"\nğŸ’¡ æç¤º:")
            print(f"1. æœ€ä½³æ¨¡å‹åœ¨ç¬¬ {best_fold} æŠ˜è®­ç»ƒä¸­è·å¾—")
            print(f"2. åœ¨æµ‹è¯•é›†ä¸ŠF1åˆ†æ•°ä¸º {best_model_info['metrics']['f1']:.4f}")
            print(f"3. å¯ä»¥è°ƒæ•´é˜ˆå€¼ï¼ˆé»˜è®¤0.5ï¼‰æ¥å¹³è¡¡ç²¾ç¡®ç‡å’Œå¬å›ç‡")
    else:
        print("è¯„ä¼°å¤±è´¥ï¼Œè¯·æ£€æŸ¥æµ‹è¯•é›†æ–‡ä»¶")

if __name__ == "__main__":
    main()